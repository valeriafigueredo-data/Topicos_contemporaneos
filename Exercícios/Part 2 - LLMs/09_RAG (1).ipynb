{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Nono Trabalho**\n",
        "\n",
        "**Nome: ValÃ©ria Cristina A. R. de Figueredo**"
      ],
      "metadata": {
        "id": "CRcjW5_Iyakd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install langchain langchain_openai langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqv8KOFU3ChF",
        "outputId": "6db41c63-d5a6-4054-d579-935c31730d19"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.10/dist-packages (0.2.14)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.26 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.28)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.3)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.58.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.8.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.7.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.23.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.26->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.26->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.26->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain_openai) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.26->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install langchain-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GT17VhKiTtjp",
        "outputId": "863685d7-cad6-43e4-83de-389c2c272ac7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.10/dist-packages (0.2.14)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.3.28)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.58.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.8.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (0.2.3)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (2.10.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-openai) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.27->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.27->langchain-openai) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEJjYVEFEq6L",
        "outputId": "40549e89-f347-4b4e-d086-091614cbd9b6"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.9.0.post1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "sykgZ2wtyWtx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b31a0a1a-9be2-43f2-9ec1-fe26d35ae2ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQ0dUCxVyWtz"
      },
      "source": [
        "## Retrieval Augmented Generation (RAG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QrAfKnuyWt1"
      },
      "source": [
        "### Carregando Documentos - Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "FYXPjHYhyWt1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb052423-481f-4ae5-d25b-a29187e138dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4301"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "#https://python.langchain.com/v0.2/docs/how_to/ #document-loaders\n",
        "#https://python.langchain.com/v0.2/docs/integrations/document_loaders/\n",
        "\n",
        "import bs4\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "# Filtra o conteÃºdo da pÃ¡gina por uma classe especÃ­fica\n",
        "bs4_strainer = bs4.SoupStrainer(class_=(\"container-wrapper\"))\n",
        "\n",
        "# Carrega o conteÃºdo da pÃ¡gina\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\"https://cesar.breezy.hr/p/00f79174d8ad-pesquisador-em-inteligencia-artificial-e-sistemas-distribuidos\",),\n",
        "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
        ")\n",
        "\n",
        "# Carrega o conteÃºdo da pÃ¡gina\n",
        "docs = loader.load()\n",
        "\n",
        "len(docs[0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixqyoxBfCVLe",
        "outputId": "1c648ba0-cc3e-4cb7-ea0a-4f6c9f98a551"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "%HEADER_COMPANY_WEBSITE%%HEADER_EMPLOYEES%%BREADCRUMB_JOB_OPENINGS%Pesquisador em InteligÃªncia Artificial e Sistemas DistribuÃ­dos%BUTTON_APPLY_TO_POSITION%%BUTTON_APPLY_USING_INDEED%%BUTTON_APPLY_USING_LINKED_IN%OlÃ¡, nÃ³s somos o CESAR! \n",
            "Somos um centro de inovaÃ§Ã£o e educaÃ§Ã£o que, hÃ¡ quase 30 anos, forma pessoas e impulsiona organizaÃ§Ãµes, potencializando suas estratÃ©gias digitais. Nosso foco estÃ¡ em resolver problemas complexos e desafiadores em um ambiente de trabalho descontraÃ­do e descentralizado, com inÃºmeros benefÃ­cios para nossos colaboradores. Aqui, vocÃª serÃ¡ protagonista, interagindo diretamente com clientes de escala global.\n",
            "Como Pesquisador em InteligÃªncia Artificial e Sistemas DistribuÃ­dos, sua missÃ£o serÃ¡ conduzir pesquisas inovadoras, integrando IA e sistemas distribuÃ­dos com foco em ciberseguranÃ§a. VocÃª vai transformar pesquisas em soluÃ§Ãµes escalÃ¡veis, colaborar com equipes multidisciplinares e compartilhar boas prÃ¡ticas para impulsionar avanÃ§os tecnolÃ³gicos. EstÃ¡ pronto para essa jornada de inovaÃ§Ã£o e impacto? Vamos nessa!Esperamos que vocÃª: \n",
            "Contribua para a construÃ§Ã£o de soluÃ§Ãµes inovadoras integrando InteligÃªncia Artificial e Sistemas DistribuÃ­dos, com foco em detecÃ§Ã£o de anomalias e ciberseguranÃ§a;Atue de forma autÃ´noma, aplicando pesquisas de ponta para resolver problemas reais de ciberseguranÃ§a em ambientes de cloud;Identifique riscos potenciais com base em mÃ©tricas de desempenho, participando ativamente na mitigaÃ§Ã£o e criaÃ§Ã£o de soluÃ§Ãµes alternativas;Colabore no planejamento e priorizaÃ§Ã£o das atividades de P&D, sempre buscando soluÃ§Ãµes eficientes e escalÃ¡veis para otimizaÃ§Ã£o de detecÃ§Ã£o de anomalias em ambientes na nuvem;Defina e explique suas decisÃµes tÃ©cnicas, fundamentando-as em boas prÃ¡ticas de design de sistemas e em evidÃªncias obtidas por meio de sua pesquisa, detalhando as soluÃ§Ãµes para garantir clareza e compreensÃ£o por toda a equipe.\n",
            "Requisitos e QualificaÃ§Ãµes:\n",
            "Doutorado em Ã¡reas correlatas;Compreenda e desenvolva modelos de machine learning e deep learning para resolver desafios complexos de ciberseguranÃ§a;Conhecimento em frameworks de machine learning como TensorFlow, PyTorch ou scikit-learn para desenvolver modelos preditivos e de detecÃ§Ã£o de anomalias aplicados Ã  ciberseguranÃ§a;Entenda a arquitetura distribuÃ­da dos sistemas e garanta a integraÃ§Ã£o eficiente de soluÃ§Ãµes de IA com aplicaÃ§Ãµes em cloud;Habilidade em manipulaÃ§Ã£o e visualizaÃ§Ã£o de dados com Pandas, NumPy, Matplotlib e Seaborn para explorar grandes volumes de dados;ExperiÃªncia com AWS, Google Cloud ou Azure para projetar e implementar infraestruturas escalÃ¡veis e resilientes;Familiaridade com Kubernetes e Docker para garantir escalabilidade e resiliÃªncia de sistemas distribuÃ­dos;ExperiÃªncia com controle de versÃ£o (Git) e repositÃ³rios remotos como GitLab;InglÃªs avanÃ§ado para leitura, escrita e comunicaÃ§Ã£o, facilitando a colaboraÃ§Ã£o com equipes globais.\n",
            "Diferenciais:\n",
            "Possuir experiÃªncia em conduzir pesquisas acadÃªmicas inovadoras, com foco em publicaÃ§Ãµes em periÃ³dicos de impacto (Qualis A2 ou superior).Conhecimento em sistemas adaptativos voltados para respostas automÃ¡ticas a anomalias e detecÃ§Ãµes de comportamentos suspeitos, permitindo que o sistema reaja proativamente a ameaÃ§as;ExperiÃªncia com ferramentas de monitoramento e anÃ¡lise de trÃ¡fego como Wireshark, Nagios ou Splunk para detectar vulnerabilidades e monitorar sistemas distribuÃ­dos;Conhecimento em automaÃ§Ã£o e DevOps, com experiÃªncia em pipelines de CI/CD, como GitHub Actions ou Jenkins, para automatizar deploys e otimizar a operaÃ§Ã£o de sistemas.\n",
            "\n",
            "Aqui no CESAR, nÃ³s temos algumas prÃ¡ticas que proporcionam uma rotina mais positiva para a pessoa colaboradora:\n",
            "HorÃ¡rio flexÃ­velEstrutura horizontalProgramas de treinamento e desenvolvimentoCultura voltada para a Diversidade & InclusÃ£o, onde vocÃª pode ser livre pra ser quem Ã©!\n",
            "Gostou? Espera sÃ³ para conferir nosso pacote variado de benefÃ­cios:\n",
            "Plano de saÃºde e odontolÃ³gicoVale RefeiÃ§Ã£o/ AlimentaÃ§Ã£oAuxÃ­lio Home OfficeAuxÃ­lio IdiomasAuxÃ­lio CrecheAuxÃ­lio Lentes de ContatoSeguro de VidaDescontos em cursos da CESAR SchoolDayOff (no AniversÃ¡rio)GympassMoodar\n",
            "Quer conhecer melhor o CESAR? Clica aqui e vem com a gente!\n",
            "#inovacaocesar #vemprocesar #soucesar%BUTTON_APPLY_TO_POSITION%%BUTTON_APPLY_USING_INDEED%%BUTTON_APPLY_USING_LINKED_IN%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcP722ikyWt2"
      },
      "source": [
        "### Dividindo Documentos - Splitting/Chunking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Nj36f54ByWt3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "480e0e2c-1a77-4e4b-93e2-429325b772a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "# https://python.langchain.com/v0.2/docs/how_to/#text-splitters\n",
        "\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000, chunk_overlap=500, add_start_index=True\n",
        ")\n",
        "all_splits = text_splitter.split_documents(docs)\n",
        "\n",
        "len(all_splits)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_splits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYJj_ZtiDorO",
        "outputId": "8ef4181f-aa77-4cae-9680-3341a7692508"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'https://cesar.breezy.hr/p/00f79174d8ad-pesquisador-em-inteligencia-artificial-e-sistemas-distribuidos', 'start_index': 0}, page_content='%HEADER_COMPANY_WEBSITE%%HEADER_EMPLOYEES%%BREADCRUMB_JOB_OPENINGS%Pesquisador em InteligÃªncia Artificial e Sistemas DistribuÃ­dos%BUTTON_APPLY_TO_POSITION%%BUTTON_APPLY_USING_INDEED%%BUTTON_APPLY_USING_LINKED_IN%OlÃ¡, nÃ³s somos o CESAR! \\nSomos um centro de inovaÃ§Ã£o e educaÃ§Ã£o que, hÃ¡ quase 30 anos, forma pessoas e impulsiona organizaÃ§Ãµes, potencializando suas estratÃ©gias digitais. Nosso foco estÃ¡ em resolver problemas complexos e desafiadores em um ambiente de trabalho descontraÃ­do e descentralizado, com inÃºmeros benefÃ­cios para nossos colaboradores. Aqui, vocÃª serÃ¡ protagonista, interagindo diretamente com clientes de escala global.'),\n",
              " Document(metadata={'source': 'https://cesar.breezy.hr/p/00f79174d8ad-pesquisador-em-inteligencia-artificial-e-sistemas-distribuidos', 'start_index': 237}, page_content='Somos um centro de inovaÃ§Ã£o e educaÃ§Ã£o que, hÃ¡ quase 30 anos, forma pessoas e impulsiona organizaÃ§Ãµes, potencializando suas estratÃ©gias digitais. Nosso foco estÃ¡ em resolver problemas complexos e desafiadores em um ambiente de trabalho descontraÃ­do e descentralizado, com inÃºmeros benefÃ­cios para nossos colaboradores. Aqui, vocÃª serÃ¡ protagonista, interagindo diretamente com clientes de escala global.\\nComo Pesquisador em InteligÃªncia Artificial e Sistemas DistribuÃ­dos, sua missÃ£o serÃ¡ conduzir pesquisas inovadoras, integrando IA e sistemas distribuÃ­dos com foco em ciberseguranÃ§a. VocÃª vai transformar pesquisas em soluÃ§Ãµes escalÃ¡veis, colaborar com equipes multidisciplinares e compartilhar boas prÃ¡ticas para impulsionar avanÃ§os tecnolÃ³gicos. EstÃ¡ pronto para essa jornada de inovaÃ§Ã£o e impacto? Vamos nessa!Esperamos que vocÃª:'),\n",
              " Document(metadata={'source': 'https://cesar.breezy.hr/p/00f79174d8ad-pesquisador-em-inteligencia-artificial-e-sistemas-distribuidos', 'start_index': 1073}, page_content='Contribua para a construÃ§Ã£o de soluÃ§Ãµes inovadoras integrando InteligÃªncia Artificial e Sistemas DistribuÃ­dos, com foco em detecÃ§Ã£o de anomalias e ciberseguranÃ§a;Atue de forma autÃ´noma, aplicando pesquisas de ponta para resolver problemas reais de ciberseguranÃ§a em ambientes de cloud;Identifique riscos potenciais com base em mÃ©tricas de desempenho, participando ativamente na mitigaÃ§Ã£o e criaÃ§Ã£o de soluÃ§Ãµes alternativas;Colabore no planejamento e priorizaÃ§Ã£o das atividades de P&D, sempre buscando soluÃ§Ãµes eficientes e escalÃ¡veis para otimizaÃ§Ã£o de detecÃ§Ã£o de anomalias em ambientes na nuvem;Defina e explique suas decisÃµes tÃ©cnicas, fundamentando-as em boas prÃ¡ticas de design de sistemas e em evidÃªncias obtidas por meio de sua pesquisa, detalhando as soluÃ§Ãµes para garantir clareza e compreensÃ£o por toda a equipe.\\nRequisitos e QualificaÃ§Ãµes:'),\n",
              " Document(metadata={'source': 'https://cesar.breezy.hr/p/00f79174d8ad-pesquisador-em-inteligencia-artificial-e-sistemas-distribuidos', 'start_index': 1896}, page_content='Requisitos e QualificaÃ§Ãµes:\\nDoutorado em Ã¡reas correlatas;Compreenda e desenvolva modelos de machine learning e deep learning para resolver desafios complexos de ciberseguranÃ§a;Conhecimento em frameworks de machine learning como TensorFlow, PyTorch ou scikit-learn para desenvolver modelos preditivos e de detecÃ§Ã£o de anomalias aplicados Ã  ciberseguranÃ§a;Entenda a arquitetura distribuÃ­da dos sistemas e garanta a integraÃ§Ã£o eficiente de soluÃ§Ãµes de IA com aplicaÃ§Ãµes em cloud;Habilidade em manipulaÃ§Ã£o e visualizaÃ§Ã£o de dados com Pandas, NumPy, Matplotlib e Seaborn para explorar grandes volumes de dados;ExperiÃªncia com AWS, Google Cloud ou Azure para projetar e implementar infraestruturas escalÃ¡veis e resilientes;Familiaridade com Kubernetes e Docker para garantir escalabilidade e resiliÃªncia de sistemas distribuÃ­dos;ExperiÃªncia com controle de versÃ£o (Git) e repositÃ³rios remotos como GitLab;InglÃªs avanÃ§ado para leitura, escrita e comunicaÃ§Ã£o, facilitando a colaboraÃ§Ã£o com equipes globais.'),\n",
              " Document(metadata={'source': 'https://cesar.breezy.hr/p/00f79174d8ad-pesquisador-em-inteligencia-artificial-e-sistemas-distribuidos', 'start_index': 2896}, page_content='Diferenciais:\\nPossuir experiÃªncia em conduzir pesquisas acadÃªmicas inovadoras, com foco em publicaÃ§Ãµes em periÃ³dicos de impacto (Qualis A2 ou superior).Conhecimento em sistemas adaptativos voltados para respostas automÃ¡ticas a anomalias e detecÃ§Ãµes de comportamentos suspeitos, permitindo que o sistema reaja proativamente a ameaÃ§as;ExperiÃªncia com ferramentas de monitoramento e anÃ¡lise de trÃ¡fego como Wireshark, Nagios ou Splunk para detectar vulnerabilidades e monitorar sistemas distribuÃ­dos;Conhecimento em automaÃ§Ã£o e DevOps, com experiÃªncia em pipelines de CI/CD, como GitHub Actions ou Jenkins, para automatizar deploys e otimizar a operaÃ§Ã£o de sistemas.'),\n",
              " Document(metadata={'source': 'https://cesar.breezy.hr/p/00f79174d8ad-pesquisador-em-inteligencia-artificial-e-sistemas-distribuidos', 'start_index': 3561}, page_content='Aqui no CESAR, nÃ³s temos algumas prÃ¡ticas que proporcionam uma rotina mais positiva para a pessoa colaboradora:\\nHorÃ¡rio flexÃ­velEstrutura horizontalProgramas de treinamento e desenvolvimentoCultura voltada para a Diversidade & InclusÃ£o, onde vocÃª pode ser livre pra ser quem Ã©!\\nGostou? Espera sÃ³ para conferir nosso pacote variado de benefÃ­cios:\\nPlano de saÃºde e odontolÃ³gicoVale RefeiÃ§Ã£o/ AlimentaÃ§Ã£oAuxÃ­lio Home OfficeAuxÃ­lio IdiomasAuxÃ­lio CrecheAuxÃ­lio Lentes de ContatoSeguro de VidaDescontos em cursos da CESAR SchoolDayOff (no AniversÃ¡rio)GympassMoodar\\nQuer conhecer melhor o CESAR? Clica aqui e vem com a gente!\\n#inovacaocesar #vemprocesar #soucesar%BUTTON_APPLY_TO_POSITION%%BUTTON_APPLY_USING_INDEED%%BUTTON_APPLY_USING_LINKED_IN%')]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "sr7SbN37yWt3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "854afc11-bfd7-431b-fcd4-25dd92d81d0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requisitos e QualificaÃ§Ãµes:\n",
            "Doutorado em Ã¡reas correlatas;Compreenda e desenvolva modelos de machine learning e deep learning para resolver desafios complexos de ciberseguranÃ§a;Conhecimento em frameworks de machine learning como TensorFlow, PyTorch ou scikit-learn para desenvolver modelos preditivos e de detecÃ§Ã£o de anomalias aplicados Ã  ciberseguranÃ§a;Entenda a arquitetura distribuÃ­da dos sistemas e garanta a integraÃ§Ã£o eficiente de soluÃ§Ãµes de IA com aplicaÃ§Ãµes em cloud;Habilidade em manipulaÃ§Ã£o e visualizaÃ§Ã£o de dados com Pandas, NumPy, Matplotlib e Seaborn para explorar grandes volumes de dados;ExperiÃªncia com AWS, Google Cloud ou Azure para projetar e implementar infraestruturas escalÃ¡veis e resilientes;Familiaridade com Kubernetes e Docker para garantir escalabilidade e resiliÃªncia de sistemas distribuÃ­dos;ExperiÃªncia com controle de versÃ£o (Git) e repositÃ³rios remotos como GitLab;InglÃªs avanÃ§ado para leitura, escrita e comunicaÃ§Ã£o, facilitando a colaboraÃ§Ã£o com equipes globais.\n"
          ]
        }
      ],
      "source": [
        "print(all_splits[3].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTiXNUSxyWt3"
      },
      "source": [
        "### Indexando - Store"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "embeddings_model = OpenAIEmbeddings()\n"
      ],
      "metadata": {
        "id": "acZl24xPHQ5H"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "bPVSGOFUyWt4"
      },
      "outputs": [],
      "source": [
        "# https://python.langchain.com/v0.2/docs/how_to/embed_text/\n",
        "\n",
        "vectorstore = FAISS.from_documents(all_splits, OpenAIEmbeddings())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "2gWIBCzryWt4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1a63e8b-2884-4d3c-c299-8f1744715957"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
        "\n",
        "retrieved_docs = retriever.invoke(\"precisa de doutorado para a vaga?\")\n",
        "\n",
        "len(retrieved_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "QuOIP_oRyWt4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76e9edde-9797-4ad0-f914-fc7fb18922f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requisitos e QualificaÃ§Ãµes:\n",
            "Doutorado em Ã¡reas correlatas;Compreenda e desenvolva modelos de machine learning e deep learning para resolver desafios complexos de ciberseguranÃ§a;Conhecimento em frameworks de machine learning como TensorFlow, PyTorch ou scikit-learn para desenvolver modelos preditivos e de detecÃ§Ã£o de anomalias aplicados Ã  ciberseguranÃ§a;Entenda a arquitetura distribuÃ­da dos sistemas e garanta a integraÃ§Ã£o eficiente de soluÃ§Ãµes de IA com aplicaÃ§Ãµes em cloud;Habilidade em manipulaÃ§Ã£o e visualizaÃ§Ã£o de dados com Pandas, NumPy, Matplotlib e Seaborn para explorar grandes volumes de dados;ExperiÃªncia com AWS, Google Cloud ou Azure para projetar e implementar infraestruturas escalÃ¡veis e resilientes;Familiaridade com Kubernetes e Docker para garantir escalabilidade e resiliÃªncia de sistemas distribuÃ­dos;ExperiÃªncia com controle de versÃ£o (Git) e repositÃ³rios remotos como GitLab;InglÃªs avanÃ§ado para leitura, escrita e comunicaÃ§Ã£o, facilitando a colaboraÃ§Ã£o com equipes globais.\n"
          ]
        }
      ],
      "source": [
        "print(retrieved_docs[0].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EsO2VyZyWt4"
      },
      "source": [
        "### Buscando e Recuperando InformaÃ§Ãµes - Retrieve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "HATshtkiyWt5"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "system_template = \"\"\"VocÃª Ã© um assistente para tarefas de perguntas e respostas. Use os seguintes trechos de contexto recuperados para responder Ã  pergunta. Se vocÃª nÃ£o souber a resposta, apenas diga que nÃ£o sabe. Use no mÃ¡ximo duas frases e mantenha a resposta concisa e fale apenas o necessÃ¡rio.\n",
        "\n",
        "Pergunta: {question}\n",
        "\n",
        "Contexto: {context}\n",
        "\n",
        "Resposta:\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(system_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "BMLmMIi8yWt5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12be7281-834b-47bc-85b6-388bbc2e543a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HumanMessage(content='VocÃª Ã© um assistente para tarefas de perguntas e respostas. Use os seguintes trechos de contexto recuperados para responder Ã  pergunta. Se vocÃª nÃ£o souber a resposta, apenas diga que nÃ£o sabe. Use no mÃ¡ximo duas frases e mantenha a resposta concisa e fale apenas o necessÃ¡rio.\\n\\nPergunta: alguma pergunta\\n\\nContexto: algum contexto\\n\\nResposta:\\n', additional_kwargs={}, response_metadata={})]\n"
          ]
        }
      ],
      "source": [
        "example_messages = prompt_template.invoke({\n",
        "    \"context\": \"algum contexto\",\n",
        "    \"question\": \"alguma pergunta\"\n",
        "})\n",
        "\n",
        "print(example_messages.to_messages())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUwSLxWGyWt5"
      },
      "source": [
        "### Gerando Respostas - Generate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "HBYAsNmkyWt5"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "Jj3Sr55xyWt5"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt_template\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "sOTZCo6RyWt5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb8309a0-ebdd-42d9-a968-28d7737bdbbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sim, o CESAR oferece plano de saÃºde como parte de seu pacote de benefÃ­cios. AlÃ©m disso, tambÃ©m disponibiliza plano odontolÃ³gico e outros auxÃ­lios."
          ]
        }
      ],
      "source": [
        "for chunk in rag_chain.stream(\"Tem plano de saÃºde como benefÃ­cio?\"):\n",
        "    print(chunk, end=\"\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtMy1RpcyWt6"
      },
      "source": [
        "## ExercÃ­cios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96UnVPq1yWt6"
      },
      "source": [
        "### ExercÃ­cio 1\n",
        "FaÃ§a um RAG com um pequeno arquivo de texto, contendo informaÃ§Ãµes que, certamente, a LLM nÃ£o conheÃ§a. VocÃª deverÃ¡ construir o arquivo e enviar para o ambiente de execuÃ§Ã£o. Escolha a forma de chunking apropriada para o seu documento."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1- CriaÃ§Ã£o de um arquivo de texto com informaÃ§Ãµes fictÃ­cias, que a LLM nÃ£o conhece\n",
        "text_content = \"\"\"\n",
        "O valor do salÃ¡rio mÃ­nimo de Lima em 2025 serÃ¡ de $ 2.320,00.\n",
        "A capital do Limoeiro Ã© Liminha, conhecida por ser o maior centro financeiro da AmÃ©rica Latina.\n",
        "O Sport Clube de Lima Ã© um dos clubes de futebol mais populares do Limoeiro, com sede na cidade de Lima.\n",
        "O Rio LimaJuice Ã© o maior rio do Limoeiro em volume de Ã¡gua e percorre parte das cidades de Liminha, Laranja e Maracuja.\n",
        "\"\"\"\n",
        "\n",
        "# Salvar o conteÃºdo em um arquivo de texto\n",
        "with open(\"informacoes.txt\", \"w\") as f:\n",
        "    f.write(text_content)\n",
        "\n",
        "\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "# 2- Carregar o arquivo de texto\n",
        "loader = TextLoader(\"informacoes.txt\")\n",
        "docs = loader.load()\n",
        "\n",
        "# Configurar o text splitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=300,  # Defina o tamanho do chunk\n",
        "    chunk_overlap=50,  # SobreposiÃ§Ã£o entre os chunks\n",
        "    add_start_index=True\n",
        ")\n",
        "\n",
        "# Dividir os documentos\n",
        "all_splits = text_splitter.split_documents(docs)\n",
        "\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# 3- Criar o vetor de embeddings a partir dos documentos\n",
        "vectorstore = FAISS.from_documents(all_splits, OpenAIEmbeddings())\n",
        "\n",
        "# 4 - Criar o retriever a partir do vectorstore\n",
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
        "\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "# 5- Definir o template do prompt\n",
        "system_template = \"\"\"\n",
        "VocÃª Ã© um assistente com tarefas de perguntas e respostas. Use os seguintes trechos de contexto recuperados para responder Ã  pergunta.\n",
        "Se vocÃª nÃ£o souber a resposta, apenas diga que nÃ£o sabe. Use no mÃ¡ximo duas frases e mantenha a resposta concisa e fale apenas o necessÃ¡rio.\n",
        "\n",
        "Pergunta: {question}\n",
        "\n",
        "Contexto: {context}\n",
        "\n",
        "Resposta:\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(system_template)\n",
        "\n",
        "example_messages = prompt_template.invoke({\n",
        "    \"context\": \"algum contexto\",\n",
        "    \"question\": \"alguma pergunta\"\n",
        "})\n",
        "\n",
        "print(example_messages.to_messages())\n",
        "\n",
        "#gerando respostas\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# 6- Usar o modelo de linguagem GPT\n",
        "llm = ChatOpenAI(model=\"gpt-4\")\n",
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt_template\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "\n",
        "for chunk in rag_chain.stream(\"Qual Ã© a capital do Limoeiro?\"):\n",
        "    print(chunk, end=\"\", flush=True)\n",
        "#resposta\n",
        "# A capital do Limoeiro Ã© Liminha. (informaÃ§Ã£o falsa)"
      ],
      "metadata": {
        "id": "BFtsbRdV0XlB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fbabeb6-cb62-4ee6-b4d1-832fc44918f0"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HumanMessage(content='\\nVocÃª Ã© um assistente com tarefas de perguntas e respostas. Use os seguintes trechos de contexto recuperados para responder Ã  pergunta.\\nSe vocÃª nÃ£o souber a resposta, apenas diga que nÃ£o sabe. Use no mÃ¡ximo duas frases e mantenha a resposta concisa e fale apenas o necessÃ¡rio.\\n\\nPergunta: alguma pergunta\\n\\nContexto: algum contexto\\n\\nResposta:\\n', additional_kwargs={}, response_metadata={})]\n",
            "A capital do Limoeiro Ã© Liminha."
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}