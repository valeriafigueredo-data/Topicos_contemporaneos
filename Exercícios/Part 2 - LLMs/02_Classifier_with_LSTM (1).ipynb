{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Segundo Trabalho**\n",
        "\n",
        "**Nome: Valéria Cristina A. R. de Figueredo**"
      ],
      "metadata": {
        "id": "2yQDcbzVJGyf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qleP1_ib8gV2"
      },
      "source": [
        "### **Introdução às LSTMs (Long Short-Term Memory)**\n",
        "\n",
        "As redes LSTM (Long Short-Term Memory) são um tipo especial de RNN projetada para lidar com o problema de dependências de longo prazo em sequências de dados. Elas são amplamente utilizadas em tarefas de processamento de linguagem natural, reconhecimento de fala, e outras aplicações que envolvem sequências.\n",
        "\n",
        "#### **Por que LSTMs?**\n",
        "\n",
        "Em RNNs tradicionais, o problema de desvanecimento de gradientes pode dificultar o aprendizado de dependências de longo prazo. As LSTMs resolvem esse problema através de uma arquitetura de memória mais complexa, que inclui células de memória capazes de preservar informações ao longo de várias etapas de tempo.\n",
        "\n",
        "#### **Arquitetura de uma LSTM**\n",
        "\n",
        "As LSTMs introduzem três \"portas\" (gates) principais para controlar o fluxo de informações:\n",
        "- **Porta de Entrada (Input Gate)**: Controla quanta informação da entrada atual deve ser armazenada na célula de memória.\n",
        "- **Porta de Esquecimento (Forget Gate)**: Decide quanta informação da célula de memória anterior deve ser mantida.\n",
        "- **Porta de Saída (Output Gate)**: Controla quanta informação da célula de memória deve ser utilizada para produzir a saída atual.\n",
        "\n",
        "Matematicamente, a atualização de uma célula LSTM pode ser descrita pelas seguintes equações:\n",
        "\n",
        "$$\n",
        "f_t = \\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f)\n",
        "$$\n",
        "$$\n",
        "i_t = \\sigma(W_i \\cdot [h_{t-1}, x_t] + b_i)\n",
        "$$\n",
        "$$\n",
        "\\tilde{C}_t = \\tanh(W_C \\cdot [h_{t-1}, x_t] + b_C)\n",
        "$$\n",
        "$$\n",
        "C_t = f_t \\cdot C_{t-1} + i_t \\cdot \\tilde{C}_t\n",
        "$$\n",
        "$$\n",
        "o_t = \\sigma(W_o \\cdot [h_{t-1}, x_t] + b_o)\n",
        "$$\n",
        "$$\n",
        "h_t = o_t \\cdot \\tanh(C_t)\n",
        "$$\n",
        "\n",
        "Onde:\n",
        "- $f_t$, $i_t$, $o_t$ são as portas de esquecimento, entrada e saída, respectivamente.\n",
        "- $C_t$ é o estado da célula.\n",
        "- $h_t$ é o estado oculto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "74wHeHQu8gV3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T16G_-Ty8gV4"
      },
      "source": [
        "### **Primeiros Passos com LSTM - Entradas Aleatórias**\n",
        "\n",
        "Vamos começar criando uma LSTM simples e alimentá-la com entradas aleatórias. Isso nos ajudará a entender como a LSTM processa os dados e o formato das saídas.\n",
        "\n",
        "#### **Explicação do Código**\n",
        "\n",
        "- **`nn.LSTM`**: Implementa uma LSTM básica com uma ou mais camadas.\n",
        "- **Parâmetros principais**:\n",
        "  - `input_size`: Dimensão das entradas em cada passo de tempo.\n",
        "  - `hidden_size`: Número de unidades na célula LSTM.\n",
        "  - `num_layers`: Número de camadas empilhadas de LSTM.\n",
        "  - `batch_first=True`: Faz com que o batch seja a primeira dimensão no tensor de entrada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_UfEOGWP8gV4"
      },
      "outputs": [],
      "source": [
        "# Configurações\n",
        "input_size = 5  # Tamanho da entrada em cada passo de tempo\n",
        "hidden_size = 10  # Número de unidades na camada oculta\n",
        "num_layers = 2  # Número de camadas empilhadas\n",
        "\n",
        "# Criando uma LSTM\n",
        "lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hK7kbSwn8gV4"
      },
      "outputs": [],
      "source": [
        "# Criando uma entrada aleatória: (batch_size, seq_len, input_size)\n",
        "batch_size = 8\n",
        "seq_len = 7\n",
        "x = torch.randn(batch_size, seq_len, input_size)\n",
        "\n",
        "# Executando a LSTM\n",
        "output, (hn, cn) = lstm(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibsWbASj8gV4"
      },
      "source": [
        "### **Interpretação das Saídas da LSTM**\n",
        "\n",
        "Vamos analisar o que as diferentes saídas da LSTM significam:\n",
        "\n",
        "- **`output`**: Contém a saída de cada passo de tempo para cada sequência no batch. A forma será `(batch_size, seq_len, hidden_size)`.\n",
        "- **`hn`**: O estado oculto final para cada camada e cada sequência no batch. A forma será `(num_layers, batch_size, hidden_size)`.\n",
        "- **`cn`**: O estado da célula final para cada camada e cada sequência no batch. A forma será a mesma que `hn`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Po6cbD708gV4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c4e3e4a-ae92-49c7-aa3d-df2d74113c27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape da saída:  torch.Size([8, 7, 10])\n",
            "Shape do estado oculto hn:  torch.Size([2, 8, 10])\n",
            "Shape do estado da célula cn:  torch.Size([2, 8, 10])\n"
          ]
        }
      ],
      "source": [
        "# Analisando as saídas\n",
        "print(\"Shape da saída: \", output.shape)\n",
        "print(\"Shape do estado oculto hn: \", hn.shape)\n",
        "print(\"Shape do estado da célula cn: \", cn.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QCb4vh0p8gV4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff424ceb-0327-4ef0-fb39-9679e86df6bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Novo comprimento da sequência: 5\n",
            "Shape da saída:  torch.Size([8, 5, 10])\n",
            "Shape do estado oculto hn:  torch.Size([2, 8, 10])\n",
            "Shape do estado da célula cn:  torch.Size([2, 8, 10])\n",
            "\n",
            "Novo tamanho do batch: 32\n",
            "Shape da saída:  torch.Size([32, 5, 10])\n",
            "Shape do estado oculto hn:  torch.Size([2, 32, 10])\n",
            "Shape do estado da célula cn:  torch.Size([2, 32, 10])\n"
          ]
        }
      ],
      "source": [
        "# Modificando o comprimento da sequência\n",
        "seq_len = 5\n",
        "x = torch.randn(batch_size, seq_len, input_size)\n",
        "output, (hn, cn) = lstm(x)\n",
        "\n",
        "print(\"Novo comprimento da sequência:\", seq_len)\n",
        "print(\"Shape da saída: \", output.shape)\n",
        "print(\"Shape do estado oculto hn: \", hn.shape)\n",
        "print(\"Shape do estado da célula cn: \", cn.shape)\n",
        "\n",
        "# Modificando o tamanho do batch\n",
        "batch_size = 32\n",
        "x = torch.randn(batch_size, seq_len, input_size)\n",
        "output, (hn, cn) = lstm(x)\n",
        "\n",
        "print(\"\\nNovo tamanho do batch:\", batch_size)\n",
        "print(\"Shape da saída: \", output.shape)\n",
        "print(\"Shape do estado oculto hn: \", hn.shape)\n",
        "print(\"Shape do estado da célula cn: \", cn.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahdbjyBw8gV4"
      },
      "source": [
        "### **Usando um Estado Inicial de LSTM**\n",
        "\n",
        "Normalmente, as LSTMs começam com um estado oculto e um estado de célula inicializados como zeros. No entanto, podemos fornecer estados iniciais personalizados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dJ6MiF3H8gV4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3134e0f-ca3e-4d55-9de2-b99a8fbfa94a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape da saída:  torch.Size([32, 5, 10])\n",
            "Shape do estado oculto hn:  torch.Size([2, 32, 10])\n",
            "Shape do estado da célula cn:  torch.Size([2, 32, 10])\n"
          ]
        }
      ],
      "source": [
        "# Estado inicial personalizado\n",
        "h0 = torch.randn(num_layers, batch_size, hidden_size)\n",
        "c0 = torch.randn(num_layers, batch_size, hidden_size)\n",
        "\n",
        "# Executando a LSTM com estados iniciais personalizados\n",
        "output, (hn, cn) = lstm(x, (h0, c0))\n",
        "\n",
        "print(\"Shape da saída: \", output.shape)\n",
        "print(\"Shape do estado oculto hn: \", hn.shape)\n",
        "print(\"Shape do estado da célula cn: \", cn.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPLh7an98gV5"
      },
      "source": [
        "### **Classificação de Nacionalidade de Nomes com LSTM**\n",
        "\n",
        "Neste exemplo, vamos usar uma LSTM para classificar a nacionalidade de nomes de pessoas. O conjunto de dados contém nomes associados às suas respectivas nacionalidades. A tarefa da LSTM será aprender a classificar corretamente esses nomes em diferentes nacionalidades.\n",
        "\n",
        "#### **Descrição do Problema**\n",
        "\n",
        "Vamos utilizar um conjunto de dados que contém nomes e suas respectivas nacionalidades. A LSTM será treinada para prever a nacionalidade com base no nome dado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNrKHzQz8gV5",
        "outputId": "7a0553ee-78d4-43bd-c28a-ae394c89d924"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-27 18:35:18--  https://download.pytorch.org/tutorial/data.zip\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 3.169.137.100, 3.169.137.13, 3.169.137.102, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|3.169.137.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2882130 (2.7M) [application/zip]\n",
            "Saving to: ‘data/data.zip’\n",
            "\n",
            "data.zip            100%[===================>]   2.75M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-12-27 18:35:18 (78.7 MB/s) - ‘data/data.zip’ saved [2882130/2882130]\n",
            "\n",
            "Archive:  data/data.zip\n",
            "  inflating: ./data/eng-fra.txt      \n",
            "   creating: ./data/names/\n",
            "  inflating: ./data/names/Arabic.txt  \n",
            "  inflating: ./data/names/Chinese.txt  \n",
            "  inflating: ./data/names/Czech.txt  \n",
            "  inflating: ./data/names/Dutch.txt  \n",
            "  inflating: ./data/names/English.txt  \n",
            "  inflating: ./data/names/French.txt  \n",
            "  inflating: ./data/names/German.txt  \n",
            "  inflating: ./data/names/Greek.txt  \n",
            "  inflating: ./data/names/Irish.txt  \n",
            "  inflating: ./data/names/Italian.txt  \n",
            "  inflating: ./data/names/Japanese.txt  \n",
            "  inflating: ./data/names/Korean.txt  \n",
            "  inflating: ./data/names/Polish.txt  \n",
            "  inflating: ./data/names/Portuguese.txt  \n",
            "  inflating: ./data/names/Russian.txt  \n",
            "  inflating: ./data/names/Scottish.txt  \n",
            "  inflating: ./data/names/Spanish.txt  \n",
            "  inflating: ./data/names/Vietnamese.txt  \n"
          ]
        }
      ],
      "source": [
        "# Download do conjunto de dados em data/\n",
        "!wget -P data/ https://download.pytorch.org/tutorial/data.zip\n",
        "\n",
        "# Descompactando o arquivo\n",
        "!unzip data/data.zip -d ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2Q9L95K68gV5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import unicodedata\n",
        "import string\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UuVA3IdR8gV5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e99bfeb8-e25c-4107-822c-b4f78af01680"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: 20074\n",
            "torch.Size([6, 1, 58]) tensor([0]) Abbing German\n"
          ]
        }
      ],
      "source": [
        "class NameDataset(Dataset):\n",
        "    def __init__(self, data_path):\n",
        "        self.all_letters = \"-\" + string.ascii_letters + \" .,;'\"\n",
        "        self.n_letters = len(self.all_letters)\n",
        "        self.NULL_IDX = 0\n",
        "        self.cat2idx, self.idx2cat, self.data = self.load_data(data_path)\n",
        "        self.letter2idx = {letter: idx for idx, letter in enumerate(self.all_letters)}\n",
        "\n",
        "    # Carregar e processar os dados\n",
        "    def load_data(self, path):\n",
        "        cat2idx = {}\n",
        "        idx2cat = {}\n",
        "        data = []\n",
        "        for idx, filename in enumerate(glob.glob(path)):\n",
        "            category = os.path.splitext(os.path.basename(filename))[0]\n",
        "            cat2idx[category] = idx\n",
        "            idx2cat[idx] = category\n",
        "\n",
        "            for line in open(filename, encoding='utf-8').read().strip().split('\\n'):\n",
        "                name = self.unicode_to_ascii(line)\n",
        "                data.append((name, category))\n",
        "        return cat2idx, idx2cat, data\n",
        "\n",
        "    # Função auxiliar para remover acentos\n",
        "    def unicode_to_ascii(self, s):\n",
        "        return ''.join(\n",
        "            c for c in unicodedata.normalize('NFD', s)\n",
        "            if unicodedata.category(c) != 'Mn'\n",
        "        )\n",
        "\n",
        "    # Converter letra para tensor <1 x n_letters>\n",
        "    def letter_to_tensor(self, letter):\n",
        "        tensor = torch.zeros(1, self.n_letters)\n",
        "        tensor[0][self.letter2idx.get(letter, self.NULL_IDX)] = 1\n",
        "        return tensor\n",
        "\n",
        "    # Converter nome para tensor <name_length x 1 x n_letters>\n",
        "    def name_to_tensor(self, name):\n",
        "        tensor = torch.zeros(len(name), 1, self.n_letters)\n",
        "        for li, letter in enumerate(name):\n",
        "            tensor[li][0][self.letter2idx.get(letter, self.NULL_IDX)] = 1\n",
        "        return tensor\n",
        "\n",
        "    def tensor_to_name(self, tensor):\n",
        "        idx = torch.argmax(tensor, dim=-1)\n",
        "        return ''.join(self.all_letters[i] for i in idx)\n",
        "\n",
        "    # Retornar o tamanho do dataset\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    # Recuperar um item do dataset\n",
        "    def __getitem__(self, idx):\n",
        "        name, category = self.data[idx]\n",
        "        name = self.name_to_tensor(name)\n",
        "        category = torch.tensor([self.cat2idx[category]], dtype=torch.long)\n",
        "        return name, category\n",
        "\n",
        "# Exemplo de uso do dataset\n",
        "dataset = NameDataset('data/names/*.txt')\n",
        "\n",
        "# Exibir o tamanho do dataset e um exemplo de tensor\n",
        "print(f\"Dataset size: {len(dataset)}\")\n",
        "name, category = dataset[0]\n",
        "print(name.shape, category, dataset.tensor_to_name(name), dataset.idx2cat[category.item()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "g3Fp3fL48gV5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51f1b669-14e9-48c1-d206-1c4b839d6a70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do dataset de treinamento: 16059\n",
            "Tamanho do dataset de teste: 4015\n"
          ]
        }
      ],
      "source": [
        "# Caminho para os arquivos de dados\n",
        "data_path = 'data/names/*.txt'\n",
        "\n",
        "# Criação do dataset\n",
        "dataset = NameDataset(data_path)\n",
        "\n",
        "# Divisão do dataset em treinamento e teste\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "print(f\"Tamanho do dataset de treinamento: {len(train_dataset)}\")\n",
        "print(f\"Tamanho do dataset de teste: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "fOv5nkdF8gV5"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def collate_fn(batch):\n",
        "    names, categories = zip(*batch)\n",
        "\n",
        "    # Padding dos tensores de nomes usando o valor do caractere nulo\n",
        "    names_padded = pad_sequence(names, batch_first=True, padding_value=dataset.NULL_IDX).squeeze()\n",
        "\n",
        "    # Converte lista de categorias para tensor\n",
        "    categories = torch.cat(categories)\n",
        "\n",
        "    return names_padded, categories\n",
        "\n",
        "\n",
        "# Criação dos DataLoaders\n",
        "batch_size = 8\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "HslED_4a8gV5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97102170-9e58-412c-b44f-e3f512d7aa59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 11, 58]) torch.Size([8])\n"
          ]
        }
      ],
      "source": [
        "# Exemplo de uso do DataLoader\n",
        "names, categories = next(iter(test_loader))\n",
        "print(names.shape, categories.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "imd6-0G98gV5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5440f6fc-0db9-4e54-b416-93ecf416005b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Kassis-----', 'Arabic')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "idx = 2\n",
        "dataset.tensor_to_name(names[idx]), dataset.idx2cat[categories[idx].item()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzyC_wS88gV5"
      },
      "source": [
        "### **Treinamento do Modelo LSTM para Classificação de Nacionalidade**\n",
        "\n",
        "Vamos criar e treinar uma LSTM para classificar os nomes em diferentes nacionalidades.\n",
        "\n",
        "#### **Configuração do Modelo**\n",
        "\n",
        "- **`input_size`**: Número de letras possíveis no nome (dimensão do vetor one-hot para cada letra).\n",
        "- **`hidden_size`**: Número de unidades na camada oculta da LSTM.\n",
        "- **`output_size`**: Número de categorias (nacionalidades).\n",
        "- **`num_layers`**: Número de camadas LSTM empilhadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "IaUGGprJ8gV5"
      },
      "outputs": [],
      "source": [
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, h=None):\n",
        "        # x: (batch_size, seq_len, input_size)\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "\n",
        "        # h: (num_layers, batch_size, hidden_size)\n",
        "        if h is None:\n",
        "            h = (torch.zeros(self.lstm.num_layers, batch_size, self.lstm.hidden_size).to(x.device),\n",
        "                 torch.zeros(self.lstm.num_layers, batch_size, self.lstm.hidden_size).to(x.device))\n",
        "\n",
        "        # Processa a sequência com a LSTM\n",
        "        out, (hn, cn) = self.lstm(x, h)\n",
        "\n",
        "        # Apenas a última saída de tempo é usada para classificação\n",
        "        out = out[:, -1, :]\n",
        "\n",
        "        # Calcula a saída\n",
        "        y = self.fc(out)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "KJ3fEA_p8gV5"
      },
      "outputs": [],
      "source": [
        "# Configuração do modelo\n",
        "input_size = dataset.n_letters\n",
        "hidden_size = 128\n",
        "output_size = len(dataset.cat2idx)  # Número de nacionalidades\n",
        "num_layers = 1\n",
        "\n",
        "model = LSTMClassifier(input_size, hidden_size, output_size, num_layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ztdcCHD08gV5"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ZIyk-7Iw8gV5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ae878bc-c840-4a68-fe4c-4728d2c4bd98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:11<00:00, 168.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 1.204185962677002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:11<00:00, 174.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.2280656099319458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:11<00:00, 172.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 1.9897546768188477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:11<00:00, 180.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Loss: 0.1599954217672348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:11<00:00, 179.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Loss: 0.07012324780225754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:11<00:00, 176.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Loss: 0.02435113489627838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:11<00:00, 175.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Loss: 0.21865063905715942\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:11<00:00, 175.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Loss: 0.6465805768966675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:11<00:00, 178.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Loss: 0.5404890775680542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:11<00:00, 173.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Loss: 0.4464627802371979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Treinamento\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for names, categories in tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(names)\n",
        "        loss = criterion(outputs, categories.squeeze())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WpiWfjR8gV5"
      },
      "source": [
        "### **Avaliação do Modelo**\n",
        "\n",
        "Após o treinamento, vamos avaliar o modelo no conjunto de teste para verificar como ele se sai na classificação das nacionalidades."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "kIOa3Th08gV6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5b29320-38f1-4a5a-f5a0-7fe0686eb371"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia no conjunto de teste: 79.58%\n"
          ]
        }
      ],
      "source": [
        "# Avaliação do modelo\n",
        "model.eval()\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for names, categories in test_loader:\n",
        "        outputs = model(names)\n",
        "        predicted = torch.argmax(outputs, dim=1)\n",
        "        correct += (predicted == categories.squeeze()).sum().item()\n",
        "\n",
        "accuracy = correct / len(test_dataset)\n",
        "print(f'Acurácia no conjunto de teste: {accuracy * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qG9GvzN8gV6"
      },
      "source": [
        "### **Visualização de Resultados**\n",
        "\n",
        "Finalmente, podemos visualizar algumas das classificações feitas pelo modelo para verificar como ele está tomando as decisões."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Q5aYv4Vm8gV6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b14ca83c-20d1-4a98-834c-ae3f3145c9fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nome: Dykes | Nacionalidade Real: English | Predição: Greek\n",
            "\n",
            "Nome: Glatter | Nacionalidade Real: Czech | Predição: English\n",
            "\n",
            "Nome: Boveri | Nacionalidade Real: Italian | Predição: Italian\n",
            "\n",
            "Nome: Carey | Nacionalidade Real: Irish | Predição: English\n",
            "\n",
            "Nome: Moklyachenko | Nacionalidade Real: Russian | Predição: Russian\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for _ in range(5):\n",
        "    i = np.random.randint(len(test_dataset))\n",
        "    name_tensor, category = test_dataset[i]\n",
        "    name_tensor = name_tensor.squeeze().unsqueeze(0)\n",
        "    name = dataset.tensor_to_name(name_tensor[0])\n",
        "    category = category.item()\n",
        "\n",
        "    output = model(name_tensor)\n",
        "    predicted = output.argmax(-1).item()\n",
        "    print(f\"Nome: {name} | Nacionalidade Real: {dataset.idx2cat[category]} | Predição: {dataset.idx2cat[predicted]}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkJdmIB78gV6"
      },
      "source": [
        "## Exercícios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BM97YhJ8gV6"
      },
      "source": [
        "### Exercício 1\n",
        "Aumente o número de camadas para 2 e treine o modelo. O que acontece com os resultados?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ikySwu1p1INS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3f57f3f-81ce-40fe-b365-bec7444334ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:19<00:00, 104.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 1.0121232271194458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:19<00:00, 105.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.71458101272583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:19<00:00, 102.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 0.9815358519554138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:19<00:00, 101.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Loss: 1.3523011207580566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:18<00:00, 106.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Loss: 0.8727906346321106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:19<00:00, 101.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Loss: 0.18712298572063446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:19<00:00, 105.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Loss: 0.49261561036109924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:19<00:00, 101.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Loss: 0.017978204414248466\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:18<00:00, 107.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Loss: 0.014322638511657715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2008/2008 [00:19<00:00, 102.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Loss: 0.0007158782100304961\n",
            "Acurácia no conjunto de teste: 79.90%\n",
            "Nome: Harlow | Nacionalidade Real: English | Predição: English\n",
            "\n",
            "Nome: Mifsud | Nacionalidade Real: Arabic | Predição: Arabic\n",
            "\n",
            "Nome: Tchehovsky | Nacionalidade Real: Russian | Predição: Russian\n",
            "\n",
            "Nome: Porshenkov | Nacionalidade Real: Russian | Predição: Russian\n",
            "\n",
            "Nome: Hirano | Nacionalidade Real: Japanese | Predição: Japanese\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers=2):\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, h=None):\n",
        "        # x: (batch_size, seq_len, input_size)\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "\n",
        "        # h: (num_layers, batch_size, hidden_size)\n",
        "        if h is None:\n",
        "            h = (torch.zeros(self.lstm.num_layers, batch_size, self.lstm.hidden_size).to(x.device),\n",
        "                 torch.zeros(self.lstm.num_layers, batch_size, self.lstm.hidden_size).to(x.device))\n",
        "\n",
        "        # Processa a sequência com a LSTM\n",
        "        out, (hn, cn) = self.lstm(x, h)\n",
        "\n",
        "        # Apenas a última saída de tempo é usada para classificação\n",
        "        out = out[:, -1, :]\n",
        "\n",
        "        # Calcula a saída\n",
        "        y = self.fc(out)\n",
        "        return y\n",
        "\n",
        "# Configuração do modelo\n",
        "input_size = dataset.n_letters\n",
        "hidden_size = 128\n",
        "output_size = len(dataset.cat2idx)  # Número de nacionalidades\n",
        "num_layers = 2\n",
        "\n",
        "model = LSTMClassifier(input_size, hidden_size, output_size, num_layers)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "# Treinamento\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for names, categories in tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(names)\n",
        "        loss = criterion(outputs, categories.squeeze())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
        "\n",
        "# Avaliação do modelo\n",
        "model.eval()\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for names, categories in test_loader:\n",
        "        outputs = model(names)\n",
        "        predicted = torch.argmax(outputs, dim=1)\n",
        "        correct += (predicted == categories.squeeze()).sum().item()\n",
        "\n",
        "accuracy = correct / len(test_dataset)\n",
        "print(f'Acurácia no conjunto de teste: {accuracy * 100:.2f}%')\n",
        "\n",
        "for _ in range(5):\n",
        "    i = np.random.randint(len(test_dataset))\n",
        "    name_tensor, category = test_dataset[i]\n",
        "    name_tensor = name_tensor.squeeze().unsqueeze(0)\n",
        "    name = dataset.tensor_to_name(name_tensor[0])\n",
        "    category = category.item()\n",
        "\n",
        "    output = model(name_tensor)\n",
        "    predicted = output.argmax(-1).item()\n",
        "    print(f\"Nome: {name} | Nacionalidade Real: {dataset.idx2cat[category]} | Predição: {dataset.idx2cat[predicted]}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0H8Q27Hw42s"
      },
      "source": [
        "O aumento do número de camadas da LSTM para 2 resultou em uma acurácia mais alta. Entretanto, o modelo se comportou de modo similar com relação a instabiblidade da perda, isto é, a perda aumentou e diminuiu ao longo das épocas treinadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUeGaED_8gV6"
      },
      "source": [
        "### Exercício 2\n",
        "Utilize o modelo treinado para fazer a predição da nacionalidade do seu nome"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Função baseada na função name_to_tensor da classe NameDataset definida no item Classificação de Nacionalidade de Nomes com LSTM\n",
        "def name_to_tensor_2(nome):\n",
        "    all_letters = \"-\" + string.ascii_letters + \" .,;'\"\n",
        "    n_letters = len(all_letters)\n",
        "    NULL_IDX = 0\n",
        "    tensor = torch.zeros(len(nome), 1, n_letters)\n",
        "    letter2idx = {letter: idx for idx, letter in enumerate(all_letters)}\n",
        "\n",
        "    for li, letter in enumerate(nome):\n",
        "        tensor[li][0][letter2idx.get(letter, NULL_IDX)] = 1\n",
        "    return tensor"
      ],
      "metadata": {
        "id": "rHimSfsNZNWP"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nome ='Valéria'\n",
        "name_tensor = name_to_tensor_2(nome=nome)\n",
        "name_tensor = name_tensor.squeeze().unsqueeze(0)\n",
        "output = model(name_tensor)\n",
        "predicted = output.argmax(-1).item()\n",
        "print(f\"Nome: {nome} | Predição: {dataset.idx2cat[predicted]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5NJ1JXDZQ6Y",
        "outputId": "5c797717-1e65-4753-e718-038dc5fa20fb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nome: Valéria | Predição: Russian\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}